# âœ… IMPROVED PIPELINE - Clear Structure

## What Changed

### âœ… Now Runs ALL 12 Prompts
- **Before**: Only 1 prompt Ã— 3 attempts = 3 visualizations
- **Now**: 12 prompts Ã— 3 attempts = **36 visualizations**

### âœ… Better File Organization
- **Before**: Outputs in `src/outputs/` (confusing)
- **Now**: Organized by prompt in `/scratch/bds9746/viz_evaluation_pipeline/outputs/` (clean)
- **Each prompt**: Gets its own folder with visualizations/, code/, and metrics/ subdirectories

### âœ… Clearer File Organization
- **Before**: All files in one folder
- **Now**: Each prompt has its own folder

Example Structure:
```
outputs/
â”œâ”€â”€ prompt_01_survival_by_class/
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt1_20251130_173000.png
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt2_20251130_173010.png
â”‚   â”‚   â””â”€â”€ llama-3.3-70b-versatile_attempt3_20251130_173020.png
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt1_20251130_173000.py
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt2_20251130_173010.py
â”‚   â”‚   â””â”€â”€ llama-3.3-70b-versatile_attempt3_20251130_173020.py
â”‚   â””â”€â”€ metrics/
â”‚       â”œâ”€â”€ llama-3.3-70b-versatile_attempt1_metrics.json
â”‚       â”œâ”€â”€ llama-3.3-70b-versatile_attempt2_metrics.json
â”‚       â””â”€â”€ llama-3.3-70b-versatile_attempt3_metrics.json
â”œâ”€â”€ prompt_02_gender_survival/
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ code/
â”‚   â””â”€â”€ metrics/
...
```

---

## ğŸ“ New Directory Structure

```
/scratch/bds9746/viz_evaluation_pipeline/
â”œâ”€â”€ venv/                          # Python environment
â”œâ”€â”€ data/
â”‚   â””â”€â”€ titanic.csv               # Dataset
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml               # Configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline_v2.py            # âœ¨ NEW: Enhanced pipeline (all prompts)
â”‚   â”œâ”€â”€ pipeline.py               # OLD: Original (1 prompt only)
â”‚   â”œâ”€â”€ prompts.py                # 12 test prompts
â”‚   â””â”€â”€ metrics.py                # Metric calculations
â”œâ”€â”€ outputs/                       # âœ¨ NEW: Organized by prompt
â”‚   â”œâ”€â”€ prompt_01_survival_by_class/
â”‚   â”‚   â”œâ”€â”€ visualizations/       # PNG files for prompt 01
â”‚   â”‚   â”œâ”€â”€ code/                 # PY files for prompt 01
â”‚   â”‚   â””â”€â”€ metrics/              # JSON metrics for prompt 01
â”‚   â”œâ”€â”€ prompt_02_gender_survival/
â”‚   â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â””â”€â”€ metrics/
â”‚   â”œâ”€â”€ ... (prompt_03 through prompt_12)
â”‚   â””â”€â”€ logs/                     # Summary reports
â”œâ”€â”€ run_all.sh                    # âœ¨ NEW: Run all 12 prompts (36 viz)
â”œâ”€â”€ run_test.sh                   # âœ¨ NEW: Quick test (2 prompts, 6 viz)
â””â”€â”€ run.sh                        # OLD: Original (1 prompt, 3 viz)
```

---

## ğŸš€ How to Use

### Option 1: Quick Test (Recommended First)
**2 prompts Ã— 3 attempts = 6 visualizations (~3 minutes)**

```bash
cd /scratch/bds9746/viz_evaluation_pipeline
./run_test.sh
```

### Option 2: Full Run
**12 prompts Ã— 3 attempts = 36 visualizations (~20-30 minutes)**

```bash
cd /scratch/bds9746/viz_evaluation_pipeline
./run_all.sh
```

### Option 3: Original (Old Way)
**1 prompt Ã— 3 attempts = 3 visualizations (~2 minutes)**

```bash
cd /scratch/bds9746/viz_evaluation_pipeline
./run.sh
```

---

## ğŸ“Š The 12 Prompts

Each prompt tests different visualization capabilities:

| ID | Prompt Name | Focus |
|----|-------------|-------|
| 01 | Survival Rate by Passenger Class | Class disparity |
| 02 | Gender-Based Survival Analysis | Gender differences |
| 03 | Age Distribution and Survival | Age patterns |
| 04 | Fare Price and Survival Correlation | Economic factors |
| 05 | Family Size Impact on Survival | Optimal family size |
| 06 | Port of Embarkation and Survival | Geographic patterns |
| 07 | Multi-Factor Survival Heatmap | Correlation analysis |
| 08 | Comprehensive Titanic Dashboard | Multi-panel overview |
| 09 | Class-Gender Interaction Effect | Interaction effects |
| 10 | Survival Decision Tree | Hierarchical patterns |
| 11 | Missing Data Pattern Analysis | Data quality |
| 12 | Fare Distribution Across Classes | Price stratification |

---

## ğŸ“ Output Files (After Full Run)

### Organized by Prompt (12 prompt folders)

Each prompt gets its own folder with all 3 attempts:

```
outputs/
â”œâ”€â”€ prompt_01_survival_by_class/
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt1_TIMESTAMP.png
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt2_TIMESTAMP.png
â”‚   â”‚   â””â”€â”€ llama-3.3-70b-versatile_attempt3_TIMESTAMP.png
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt1_TIMESTAMP.py
â”‚   â”‚   â”œâ”€â”€ llama-3.3-70b-versatile_attempt2_TIMESTAMP.py
â”‚   â”‚   â””â”€â”€ llama-3.3-70b-versatile_attempt3_TIMESTAMP.py
â”‚   â””â”€â”€ metrics/
â”‚       â”œâ”€â”€ llama-3.3-70b-versatile_attempt1_metrics.json
â”‚       â”œâ”€â”€ llama-3.3-70b-versatile_attempt2_metrics.json
â”‚       â””â”€â”€ llama-3.3-70b-versatile_attempt3_metrics.json
â”‚
â”œâ”€â”€ prompt_02_gender_survival/
â”‚   â”œâ”€â”€ visualizations/ (3 PNG files)
â”‚   â”œâ”€â”€ code/ (3 PY files)
â”‚   â””â”€â”€ metrics/ (3 JSON files)
â”‚
â”œâ”€â”€ prompt_03_age_distribution/
â”‚   â””â”€â”€ ... (same structure)
â”‚
... (prompt_04 through prompt_12, each with same structure)
â”‚
â””â”€â”€ logs/
    â”œâ”€â”€ pipeline_results_TIMESTAMP.json     # Complete results
    â””â”€â”€ summary_report_TIMESTAMP.txt        # Human-readable summary
```

**Total files: 109 files across 12 prompt folders**
- 12 prompt folders Ã— 3 attempts each:
  - 36 PNG (visualizations)
  - 36 PY (code files)
  - 36 JSON (metrics)
- Plus 2 summary files in logs/

---

## ğŸ¯ View Results

```bash
# See all prompt folders
ls /scratch/bds9746/viz_evaluation_pipeline/outputs/

# View results for a specific prompt (e.g., prompt 01)
ls /scratch/bds9746/viz_evaluation_pipeline/outputs/prompt_01_survival_by_class/

# See all visualizations for prompt 01
ls /scratch/bds9746/viz_evaluation_pipeline/outputs/prompt_01_survival_by_class/visualizations/*.png

# Count total visualizations across all prompts
find /scratch/bds9746/viz_evaluation_pipeline/outputs/prompt_*/visualizations -name "*.png" | wc -l

# View metrics for a specific attempt
cat /scratch/bds9746/viz_evaluation_pipeline/outputs/prompt_01_survival_by_class/metrics/*_attempt1*.json | python -m json.tool

# Read summary report
cat /scratch/bds9746/viz_evaluation_pipeline/outputs/logs/summary_report_*.txt

# Compare all attempts for one prompt
ls -lh /scratch/bds9746/viz_evaluation_pipeline/outputs/prompt_01_survival_by_class/visualizations/
```

---

## ğŸ“ˆ Expected Results

After running `./run_all.sh`:

```
âœ“ Total Prompts: 12
âœ“ Attempts per Prompt: 3
âœ“ Total Visualizations: 36
âœ“ Success Rate: ~80-100% (varies by prompt)
âœ“ Time: 20-30 minutes
âœ“ Output Size: ~10-15 MB
```

---

## ğŸ”§ Comparison: Old vs New

| Feature | Old (`run.sh`) | New (`run_all.sh`) |
|---------|----------------|-------------------|
| Prompts | 1 | 12 |
| Attempts per prompt | 3 | 3 |
| Total visualizations | 3 | 36 |
| Output location | `src/outputs/` | `outputs/` |
| File organization | All in one folder | Organized by prompt |
| File naming | Generic | Clean, timestamped |
| Folder structure | Flat | Hierarchical (prompt/type/) |
| Easy comparison | âŒ No | âœ… Yes - grouped by prompt |
| Time | ~2 min | ~25 min |
| Research value | Limited | Complete |

---

## ğŸ’¡ Recommendations

1. **Start with test**: Run `./run_test.sh` first to verify everything works
2. **Then full run**: Run `./run_all.sh` for complete results
3. **Review outputs**: Check `outputs/logs/summary_report_*.txt` for overview
4. **Analyze by prompt**: Group results by prompt ID to compare

---

## ğŸ“ For Your Research

The new structure gives you:

- âœ… **12 different visualization tasks** (comprehensive evaluation)
- âœ… **3 attempts each** (consistency analysis)
- âœ… **Organized by prompt** (each prompt has its own folder)
- âœ… **Separated by type** (visualizations/, code/, metrics/ in each folder)
- âœ… **Easy comparison** (all attempts for one prompt are together)
- âœ… **Clean naming** (timestamp-based, no confusion)
- âœ… **Complete metrics** (Color Î”E, Visual Entropy, Code Accuracy, etc.)
- âœ… **Research-ready structure** (perfect for analysis and comparison)

Perfect for your research paper! ğŸ“Š
