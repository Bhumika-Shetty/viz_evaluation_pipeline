# Quick Start Guide - Prompt-Organized Pipeline

## âœ¨ What's New?

Each prompt now has its own dedicated folder! This makes it easy to:
- Compare all 3 attempts for a single prompt
- Analyze prompt-specific results
- Keep visualizations, code, and metrics organized

## ğŸ“ New Folder Structure

```
outputs/
â”œâ”€â”€ prompt_01_survival_by_class/
â”‚   â”œâ”€â”€ visualizations/    # 3 PNG files (attempt 1, 2, 3)
â”‚   â”œâ”€â”€ code/             # 3 PY files  (attempt 1, 2, 3)
â”‚   â””â”€â”€ metrics/          # 3 JSON files (attempt 1, 2, 3)
â”œâ”€â”€ prompt_02_gender_survival/
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ code/
â”‚   â””â”€â”€ metrics/
â”œâ”€â”€ ... (prompt_03 through prompt_12)
â””â”€â”€ logs/
    â”œâ”€â”€ pipeline_results_TIMESTAMP.json
    â””â”€â”€ summary_report_TIMESTAMP.txt
```

## ğŸš€ Quick Commands

### Run Quick Test (2 prompts)
```bash
cd /scratch/bds9746/viz_evaluation_pipeline
./run_test.sh
```

### Run Full Pipeline (12 prompts)
```bash
cd /scratch/bds9746/viz_evaluation_pipeline
./run_all.sh
```

## ğŸ“Š View Results

### See all prompt folders
```bash
ls outputs/
```

### Check results for a specific prompt
```bash
# List all files for prompt 01
ls -R outputs/prompt_01_survival_by_class/

# View just the visualizations
ls outputs/prompt_01_survival_by_class/visualizations/

# View metrics for attempt 1
cat outputs/prompt_01_survival_by_class/metrics/*attempt1*.json | python -m json.tool
```

### Count total visualizations
```bash
find outputs/prompt_*/visualizations -name "*.png" | wc -l
```

### Compare all attempts for one prompt
```bash
# See all 3 attempts side by side
ls -lh outputs/prompt_01_survival_by_class/visualizations/
```

## ğŸ¯ Benefits for Research

### Easy Prompt Comparison
All attempts for one prompt are in the same folder - makes it easy to:
- Compare consistency across 3 attempts
- Analyze metrics for each prompt separately
- Identify which prompts work best

### Clean Organization
```
prompt_01_survival_by_class/
â”œâ”€â”€ visualizations/  â† All images here
â”œâ”€â”€ code/           â† All Python files here
â””â”€â”€ metrics/        â† All metric JSONs here
```

No more searching through a flat folder with 100+ files!

### Research Analysis Examples

**Analyze consistency for prompt 01:**
```bash
cat outputs/prompt_01_survival_by_class/metrics/*.json | \
  python -c "import sys, json; metrics = [json.loads(l) for l in sys.stdin if l.strip()]; \
  print('Mean Color Î”E:', sum(m['color_delta_e']['mean_delta_e'] for m in metrics)/len(metrics))"
```

**Compare success rates across prompts:**
```bash
for dir in outputs/prompt_*/; do
  count=$(ls $dir/visualizations/*.png 2>/dev/null | wc -l)
  echo "$(basename $dir): $count/3 successful"
done
```

## ğŸ” What Each Prompt Tests

| Prompt ID | Focus Area | Visualization Type |
|-----------|------------|-------------------|
| 01 | Survival by class | Bar chart |
| 02 | Gender survival | Comparative analysis |
| 03 | Age distribution | Histogram/density |
| 04 | Fare vs survival | Scatter/correlation |
| 05 | Family size impact | Grouped analysis |
| 06 | Embarkation patterns | Geographic/categorical |
| 07 | Multi-factor heatmap | Correlation matrix |
| 08 | Comprehensive dashboard | Multi-panel layout |
| 09 | Class-gender interaction | Interaction effects |
| 10 | Decision tree | Hierarchical patterns |
| 11 | Missing data | Data quality analysis |
| 12 | Fare distribution | Box plot/violin |

## ğŸ“ˆ Expected Output

After running `./run_all.sh`:

```
âœ“ 12 prompt folders created
âœ“ Each with 3 attempts
âœ“ Total: 36 visualizations + 36 code files + 36 metric files
âœ“ Plus 2 summary reports
```

## âš¡ Tips

1. **Start with test**: Run `./run_test.sh` first to verify everything works
2. **Check one prompt**: Navigate to a specific prompt folder to see all attempts together
3. **Compare visually**: Open all PNG files in one prompt folder to compare attempts
4. **Analyze metrics**: Each prompt's metrics are in its own folder for easy analysis

## ğŸ“ For Your Paper

This structure is perfect for research because:
- âœ… Each prompt is a separate test case
- âœ… 3 attempts measure consistency
- âœ… Easy to generate statistics per prompt
- âœ… Clean structure for figures in paper
- âœ… Organized metrics for quantitative analysis

---

**Ready to run? Start with:**
```bash
cd /scratch/bds9746/viz_evaluation_pipeline
./run_test.sh
```
